{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HvhYZrIZCEyo"
   },
   "source": [
    "<img src=\"https://user-images.githubusercontent.com/26833433/82952157-51b7db00-9f5d-11ea-8f4b-dda1ffecf992.jpg\">\n",
    "\n",
    "This notebook was written by Ultralytics LLC, and is freely available for redistribution under the [GPL-3.0 license](https://choosealicense.com/licenses/gpl-3.0/). \n",
    "For more information please visit https://github.com/ultralytics/yolov5 and https://www.ultralytics.com."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "# Setup\n",
    "\n",
    "Clone repo, install dependencies, `%cd` into `./yolov5` folder and check GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "wbvMlHd_QwMG",
    "outputId": "669566b2-391f-4596-f290-110e2e177946"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'git' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "ERROR: Invalid requirement: '#'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 2] The system cannot find the file specified: 'yolov5'\n",
      "C:\\Users\\Fazeel\\Desktop\\yolov5-master\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-768ae3109a88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cd'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'yolov5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclear_output\u001b[0m  \u001b[1;31m# to display images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgoogle_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgdrive_download\u001b[0m  \u001b[1;31m# to download models/datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5  # clone repo\n",
    "!pip install -qr yolov5/requirements.txt  # install dependencies (ignore errors)\n",
    "%cd yolov5\n",
    "\n",
    "import torch\n",
    "from IPython.display import Image, clear_output  # to display images\n",
    "from utils.google_utils import gdrive_download  # to download models/datasets\n",
    "\n",
    "clear_output()\n",
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N3qM6T0W53gh"
   },
   "source": [
    "# 1. Inference\n",
    "\n",
    "Run inference with a pretrained checkpoint on contents of `/inference/images` folder. Models are auto-downloaded from [Google Drive](https://drive.google.com/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "colab_type": "code",
    "id": "zR9ZbuQCH7FX",
    "outputId": "528fcc04-2393-437a-84d2-092becbaefbe"
   },
   "outputs": [],
   "source": [
    "!python detect.py --weights yolov5s.pt --img 416 --conf 0.4 --source inference/images/\n",
    "Image(filename='inference/output/zidane.jpg', width=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4JnkELT0cIJg"
   },
   "source": [
    "Inference can be run on a variety of sources: images, videos, directories, webcams, rtsp and http streams as shown in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WwosXmgDahte"
   },
   "outputs": [],
   "source": [
    "# Example syntax (do not run cell)\n",
    "!python detect.py --source file.jpg  # image \n",
    "                           file.mp4  # video\n",
    "                           dir/  # directory\n",
    "                           0  # webcam\n",
    "                           'rtsp://170.93.143.139/rtplive/470011e600ef003a004ee33696235daa' # rtsp\n",
    "                           'http://112.50.243.8/PLTV/88888888/224/3221225900/1.m3u8'  # http"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0eq1SMWl6Sfn"
   },
   "source": [
    "# 2. Test\n",
    "Test a model on COCO val or test-dev dataset to determine trained accuracy. Models are auto-downloaded from [Google Drive](https://drive.google.com/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J). To show results by class use the `--verbose` flag. Note that `pycocotools` metrics may be 1-2% better than the equivalent repo metrics, as is visible below, due to slight differences in mAP computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eyTZYGgRjnMc"
   },
   "source": [
    "### 2.1 val2017\n",
    "Download COCO val 2017 dataset, 1GB, 5000 images, and test model accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "WQPtK1QYVaD_",
    "outputId": "df037a5d-efae-4687-9ff7-22a48fd7f801"
   },
   "outputs": [],
   "source": [
    "# Download COCO val2017\n",
    "gdrive_download('1Y6Kou6kEB0ZEMCCpJSKStCor4KAReE43','coco2017val.zip')  # val2017 dataset\n",
    "!mv ./coco ../  # move folder alongside /yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "colab_type": "code",
    "id": "X58w8JLpMnjH",
    "outputId": "8c62a086-e312-46d1-b475-d90542eae545"
   },
   "outputs": [],
   "source": [
    "# Run YOLOv5x on COCO val2017\n",
    "!python test.py --weights yolov5x.pt --data coco.yaml --img 672"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rc_KbFk0juX2"
   },
   "source": [
    "### 2.2 test-dev2017\n",
    "Download COCO test2017 dataset, 7GB, 40,000 images, to test model accuracy on test-dev set, 20,000 images. Results are saved to a `*.json` file which can be submitted to the evaluation server at https://competitions.codalab.org/competitions/20794."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V0AJnSeCIHyJ"
   },
   "outputs": [],
   "source": [
    "# Download COCO test-dev2017\n",
    "gdrive_download('1cXZR_ckHki6nddOmcysCuuJFM--T-Q6L','coco2017labels.zip')  # annotations\n",
    "!f=\"test2017.zip\" && curl http://images.cocodataset.org/zips/$f -o $f && unzip -q $f && rm $f  # 7GB,  41k images\n",
    "!mv ./test2017 ./coco/images && mv ./coco ../  # move images into /coco and move /coco alongside /yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "29GJXAP_lPrt"
   },
   "outputs": [],
   "source": [
    "# Run YOLOv5s on COCO test-dev2017 with argument --task test\n",
    "!python test.py --weights yolov5s.pt --data ./data/coco.yaml --task test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VUOiNLtMP5aG"
   },
   "source": [
    "# 3. Train\n",
    "\n",
    "Download https://www.kaggle.com/ultralytics/coco128, a small 128-image tutorial dataset, start tensorboard and train YOLOv5s from a pretrained checkpoint for 3 epochs (actual training is much longer, around **300-1000 epochs**, depending on your dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "Knxi2ncxWffW",
    "outputId": "35815e93-7d6e-4fee-c050-a4a565d51648"
   },
   "outputs": [],
   "source": [
    "# Download coco128\n",
    "gdrive_download('1n_oKgR81BJtqk75b00eAjdv03qVCQn2f','coco128.zip')  # coco128 dataset\n",
    "!mv ./coco128 ../  # move folder alongside /yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_pOkGLv1dMqh"
   },
   "source": [
    "Train a YOLOv5s model on coco128 by specifying model config file `--cfg models/yolo5s.yaml`, and dataset config file `--data data/coco128.yaml`. Start training from pretrained `--weights yolov5s.pt`, or from randomly initialized `--weights ''`. Pretrained weights are auto-downloaded from [Google Drive](https://drive.google.com/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J).\n",
    "\n",
    "**All training results are saved to `runs/exp0`** for the first experiment, then `runs/exp1`, `runs/exp2` etc. for subsequent experiments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bOy5KI2ncnWd"
   },
   "outputs": [],
   "source": [
    "# Start tensorboard (optional)\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1NcFxRcFdJ_O",
    "outputId": "121b5b2e-bc8e-4648-ee1c-8d2795176db6"
   },
   "outputs": [],
   "source": [
    "# Train YOLOv5s on coco128 for 3 epochs\n",
    "!python train.py --img 640 --batch 16 --epochs 3 --data coco128.yaml --cfg yolov5s.yaml --weights yolov5s.pt --nosave --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLI1JmHU7B0l"
   },
   "source": [
    "# 4. Visualize\n",
    "\n",
    "View `runs/exp0/train*.jpg` images to see training images, labels and augmentation effects. A **Mosaic Dataloader** is used for training (shown below), a new concept developed by Ultralytics and first featured in [YOLOv4](https://arxiv.org/abs/2004.10934)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "colab_type": "code",
    "id": "W40tI99_7BcH",
    "outputId": "1c838e44-79fe-433f-a334-59a037ee322e"
   },
   "outputs": [],
   "source": [
    "Image(filename='runs/exp0/train_batch1.jpg', width=900)  # view augmented training mosaics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7uOowJKI-Qak"
   },
   "source": [
    "View `test_batch0_gt.jpg` to see test batch 0 *ground truth* labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "colab_type": "code",
    "id": "PF9MLHDb7tB6",
    "outputId": "b7a874f7-dad3-4611-e777-56c724c7ee81"
   },
   "outputs": [],
   "source": [
    "Image(filename='runs/exp0/test_batch0_gt.jpg', width=900)  # view test image labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EGrb16Mu-jif"
   },
   "source": [
    "View `test_batch0_pred.jpg` to see test batch 0 *predictions*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "colab_type": "code",
    "id": "ycP4UTEZ82_I",
    "outputId": "c7c1238d-e0fa-4fc5-f393-bf5bce55d245"
   },
   "outputs": [],
   "source": [
    "Image(filename='runs/exp0/test_batch0_pred.jpg', width=900)  # view test image predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7KN5ghjE6ZWh"
   },
   "source": [
    "Training losses and performance metrics are saved to Tensorboard and also to a `runs/exp0/results.txt` logfile. `results.txt` is plotted as `results.png` after training completes. Partially completed `results.txt` files can be plotted with `from utils.general import plot_results; plot_results()`. Here we show YOLOv5s trained on coco128 to 300 epochs, starting from scratch (blue), and from pretrained `yolov5s.pt` (orange)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "MDznIqPF7nk3",
    "outputId": "c1146425-643e-49ab-de25-73216f0dde23"
   },
   "outputs": [],
   "source": [
    "from utils.general import plot_results; plot_results()  # plot results.txt files as results.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zelyeqbyt3GD"
   },
   "source": [
    "# Environments\n",
    "\n",
    "YOLOv5 may be run in any of the following up-to-date verified environments (with all dependencies including CUDA/CUDNN, Python and PyTorch preinstalled):\n",
    "\n",
    "- **Google Colab Notebook** with free GPU: <a href=\"https://colab.research.google.com/github/ultralytics/yolov5/blob/master/tutorial.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>\n",
    "- **Kaggle Notebook** with free GPU: [https://www.kaggle.com/ultralytics/yolov5](https://www.kaggle.com/ultralytics/yolov5)\n",
    "- **Google Cloud** Deep Learning VM. See [GCP Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/GCP-Quickstart) \n",
    "- **Docker Image** https://hub.docker.com/r/ultralytics/yolov5. See [Docker Quickstart Guide](https://github.com/ultralytics/yolov5/wiki/Docker-Quickstart) ![Docker Pulls](https://img.shields.io/docker/pulls/ultralytics/yolov5?logo=docker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IEijrePND_2I"
   },
   "source": [
    "# Appendix\n",
    "\n",
    "Optional extras below. Unit tests validate repo functionality and should be run on any PRs submitted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gI6NoBev8Ib1"
   },
   "outputs": [],
   "source": [
    "# Re-clone repo\n",
    "%cd ..\n",
    "!rm -rf yolov5 && git clone https://github.com/ultralytics/yolov5\n",
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2AvpeKfrbsT"
   },
   "outputs": [],
   "source": [
    "# Test GCP ckpt\n",
    "%%shell\n",
    "for x in best*\n",
    "do\n",
    "  gsutil cp gs://*/*/*/$x.pt .\n",
    "  python test.py --weights $x.pt --data coco.yaml --img 672\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FGH0ZjkGjejy"
   },
   "outputs": [],
   "source": [
    "# YOLOv5 unit tests\n",
    "%%shell\n",
    "cd .. && rm -rf yolov5 && git clone https://github.com/ultralytics/yolov5 && cd yolov5\n",
    "export PYTHONPATH=\"$PWD\" # to run *.py. files in subdirectories\n",
    "pip install -qr requirements.txt onnx\n",
    "python3 -c \"from utils.google_utils import *; gdrive_download('1n_oKgR81BJtqk75b00eAjdv03qVCQn2f', 'coco128.zip')\" && mv ./coco128 ../\n",
    "for x in yolov5s #yolov5m yolov5l yolov5x # models\n",
    "do\n",
    "  python train.py --weights $x.pt --cfg $x.yaml --epochs 4 --img 320 --device 0  # train\n",
    "  for di in 0 cpu # inference devices\n",
    "  do\n",
    "    python detect.py --weights $x.pt --device $di  # detect official\n",
    "    python detect.py --weights runs/exp0/weights/last.pt --device $di  # detect custom\n",
    "    python test.py --weights $x.pt --device $di # test official\n",
    "    python test.py --weights runs/exp0/weights/last.pt --device $di # test custom\n",
    "  done\n",
    "  python models/yolo.py --cfg $x.yaml # inspect\n",
    "  python models/export.py --weights $x.pt --img 640 --batch 1 # export\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "YOLOv5 Tutorial",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
